{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8665ad",
   "metadata": {},
   "source": [
    "# Welcome!\n",
    "\n",
    "Welcome to the HueDX API sample notebook. Although not a holistic dive into all the possiblities the HueDX platform has to offer, the following code blocks should be enough for any data science team to immediately begin using all core functionality related to the SignalDetector and HueCard processing.\n",
    "\n",
    "### For Additional API Details\n",
    "- Production Environment: https://hue-api.com/prod\n",
    "- Test Environment: https://hue-api.com/test\n",
    "- Documentation: https://docs.hue-api.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c6984d",
   "metadata": {},
   "source": [
    "## Step 1 - Common Imports, Variables and Utilities\n",
    "\n",
    "In order to interact with the API and its payloads, the following standard imports are recommended, but not required. You may replace any functionality with internal tools or third party libraries without affecting the API's results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb0c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_job_results(job_id):\n",
    "    payload={\"jobId\": job_id}\n",
    "    response = requests.request(\"GET\", job_url, headers=headers, params=payload)\n",
    "\n",
    "    while response.json()[0][\"status\"] != \"success\":\n",
    "        if response.json()[0][\"status\"] == \"failed\":\n",
    "            print(\"Job failed!\")\n",
    "            return response\n",
    "        time.sleep(2)\n",
    "        print(\"Waiting for job to complete...\")\n",
    "        response = requests.request(\"GET\", job_url, headers=headers, params=payload)\n",
    "\n",
    "    return requests.request(\"GET\", results_url, headers=headers, params=payload)\n",
    "\n",
    "\n",
    "upload_url = \"https://hue-api.com/prod/upload/generate-url\"\n",
    "job_url = \"https://hue-api.com/prod/jobs\"\n",
    "results_url = \"https://hue-api.com/prod/results\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43330a",
   "metadata": {},
   "source": [
    "## Step 2 - Obtain Your Credentials\n",
    "\n",
    "Use the `login` API to obtain your credentials which will need to be passed to subsequent API calls. In the following example the user's information is stored in a file called `creds.json` and contains the username, password and appToken for the HueAPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bad533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the credentials for obtaining API authorization\n",
    "with open(\"creds.json\") as f:\n",
    "    creds = json.load(f)\n",
    "\n",
    "#Configure the necessary credentials\n",
    "email = creds['email']\n",
    "password = creds['password']\n",
    "app_token = creds['appToken']\n",
    "    \n",
    "header = {\n",
    "    \"appToken\": app_token,\n",
    "    \"authorizationToken\": \"0\" # Required field, but can be left as 0 here\n",
    "}\n",
    "\n",
    "# Obtain the authorization token needed for other API calls\n",
    "login_url = \"https://hue-api.com/prod/login\"\n",
    "response = requests.post(login_url, json={\"email\": email, \"password\": password}, headers=header)\n",
    "authorization_token = response.json()[\"token\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dd22b7",
   "metadata": {},
   "source": [
    "## Step 3 - Uploading Your Image\n",
    "\n",
    "In order to upload your image, you must first retrieve a pre-signed URL using the `generate-url` API. The returned URL will then be used to `PUT` your image into cloud storage for processing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5fbe2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"format\": \"png\", \n",
    "    \"cameraMake\": \"Kyocera\", # optional\n",
    "    \"cameraModel\": \"VP-210\", # optional\n",
    "    \"cameraOSVersion\": \"1.0\", # optional\n",
    "    \"tag\": \"NewAssay\", # optional\n",
    "    \"experimentName\": \"110000 Pixel Camera Test\" # optional\n",
    "    }\n",
    "\n",
    "headers = {\"appToken\": app_token, \"authorizationToken\": authorization_token}\n",
    "\n",
    "response = requests.request(\"POST\", upload_url, headers=headers, json=payload)\n",
    "upload_loc = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './assets/sample.png'\n",
    "\n",
    "with open(filename, \"rb\") as upload_file:\n",
    "    files = {'file': (filename, upload_file)}\n",
    "    upload_response = requests.post(upload_loc['url'], data=upload_loc['fields'], files=files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc364ec2",
   "metadata": {},
   "source": [
    "# Steps 4-6 : Utilizing the Colorimetric Services\n",
    "\n",
    "Currently, the HueAPI exposes 3 primary colorimetric services that data science teams may find useful:\n",
    "\n",
    "- Colorimetric Analysis: This service provides basic analysis of a color swatch and generates independent, quantitative measures of the image.\n",
    "- HueCard Processing: This service must be combined with sample images taken using a HueCard. The HueCard processing service is responsible for registering the image (i.e. skew/warp/orientation correction), applying color correction to account for lighting differences, and extracting the ROI reaction windows from the card image.\n",
    "- Signal Detection: This service provides advanced analytics of color swatches to create multivariate, quantitative and visualized analyses of an experiment to determine experimental quality and success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3edd3",
   "metadata": {},
   "source": [
    "## Colorimetric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db519da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "payload = {\n",
    "    \"service\": \"colorimetricAnalysis\",\n",
    "    \"rawImageS3Key\": upload_loc[\"fields\"][\"key\"],\n",
    "    \"tag\": \"ColorAnalysis\", # optional\n",
    "    \"experimentName\": \"RedAnalysis\", # optional\n",
    "    \"extractRoi\": {\n",
    "        \"origin\": {\n",
    "            \"x\": 250,\n",
    "            \"y\": 250\n",
    "        },\n",
    "        \"dimensions\": {\n",
    "            \"width\": 90,\n",
    "            \"height\": 90\n",
    "        }\n",
    "    } \n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", job_url, headers=headers, json=payload)\n",
    "job_id = response.json()[\"jobId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17b0cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload={\"jobId\": job_id}\n",
    "response = requests.request(\"GET\", job_url, headers=headers, params=payload)\n",
    "\n",
    "while response.json()[0][\"status\"] != \"success\":\n",
    "    if response.json()[0][\"status\"] == \"failed\":\n",
    "        print(\"Job failed!\")\n",
    "        break\n",
    "    time.sleep(2)\n",
    "    print(\"Waiting for job to complete...\")\n",
    "    response = requests.request(\"GET\", job_url, headers=headers, params=payload)\n",
    "\n",
    "\n",
    "colorimetric_results = get_job_results(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c722d78a",
   "metadata": {},
   "source": [
    "## HueCard Processing\n",
    "\n",
    "HueCard processing uses the HueDX HueCard to process reaction samples either as a stand alone service that exposes the final corrected image or as a pipeline that uses the corrected image to run each reaction sample through a quantitative model and produce inference results. The type of processing is handled by the `invocationType` field which may be either `stand-alone` or `pipeline`. By default, the `cardProcessor` service applies color correction to the card after image registration. To toggle this on or off as a step, use the `colorCorrection` attribute.\n",
    "\n",
    "The `selectedConfigurations` object helps keep track of each reaction ROI which is automatically extracted from the image provided in `imageS3Key`.  Within the panel configurations is a `modelId` attribute. This parameter allows for easy and rapid selection of different models for the purposes of producing quantitative measurements of your assays. After a model has been developed that produces satisfactory and performant results for your assays, that modelId is considered static. The model selection for your production HueCard configuration is generally managed, chosen, and locked by your HueDx administrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd994ea2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "payload = {\n",
    "    \"service\":\"cardProcessor\",\n",
    "    \"imageS3Key\": upload_loc[\"fields\"][\"key\"],\n",
    "    \"colorCorrection\": True,\n",
    "    \"deviceTypeId\": \"HUE-LVR-1-1\",\n",
    "    \"context\": {\n",
    "        \"invocationType\": \"stand-alone\"\n",
    "    },\n",
    "    \"selectedConfigurations\": {\n",
    "        \"panel1\": {\n",
    "            \"configurationName\": \"blood\",\n",
    "            \"modelId\": \"bloodModelId\"\n",
    "        },\n",
    "        \"panel2\": {\n",
    "            \"configurationName\": \"plasma\",\n",
    "            \"modelId\": \"plasmaModelId\"\n",
    "        },\n",
    "        \"panel3\":{\n",
    "            \"configurationName\": \"blood\"\n",
    "        },\n",
    "        \"panel4\": {\n",
    "            \"configurationName\": \"blood\"\n",
    "        },\n",
    "        \"panel5\": {\n",
    "            \"configurationName\": \"blood\"\n",
    "        },\n",
    "        \"panel6\": {\n",
    "            \"configurationName\": \"blood\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", job_url, headers=headers, json=payload)\n",
    "job_id = response.json()[\"jobId\"]\n",
    "\n",
    "card_processor_results = get_job_results(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6354cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8bc215",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "card_processor_results.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb108fa",
   "metadata": {},
   "source": [
    "## Signal Detection\n",
    "\n",
    "Signal detection is the final step in the HueDX pipeline that produces meaningful insights into the colorimetric data being analyzed. This service can be run **in conjunction with or independent of** the HueCard. Please note that the HueCard processing accounts for ambient lighting conditions and their effects on color measurements. If you do not use a HueCard, you will need to ensure identical environmental lighting conditions in order to compare signal detection results across experiments.\n",
    "\n",
    "In order to supply the signal detection service with enough context to produce meaningful results, each measured ROI will need to be accompanied by a `concentration` -- a quantitative measure associated with that particular ROI. In the following example, we generate a list of s3 keys that correspond to the ROIs being submitted and a concentration that we are attempting to predict from that sample.\n",
    "\n",
    "Within signal detection there is the concept of a `criticalRange`, that is, the range within which a user wants to acheive the highest levels of accuracy (i.e. minimize the distance loss). This can be the entire measured range or just a subset of the entire range being submitted to the `signalDetector` service. There is a boolean option `useWeights` that when toggled will add weight to the critical range when attempting to build a prediction model. This is most useful in scenarios where the extrema of the measurements may not have any linear relationship or are composed of more noise than signal. In experiments where the results are highly linear, `useWeights` should not provide significantly different results.\n",
    "\n",
    "The final component of a successful signal detection run is providing a `backgroundImageS3Key`. The expectation during an experiment run is that whatever medium is being used as the background to the colorimetric reactions will also be provided to the signal detection service. For example, if a particular paper soaked in an analyte is used for testing blood samples, that sample paper, fully prepared but without a blood sample will be used as the background image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_loc = card_processor_results.json()[0][\"resultData\"][\"panels\"][0][\"s3Key\"]\n",
    "experiment_images = []\n",
    "for fake_concentration in range(1, 15):\n",
    "    experiment_images.append({\"s3Key\": sample_loc, \"concentration\": fake_concentration})\n",
    "\n",
    "payload = {\n",
    "    \"service\": \"signalDetector\",\n",
    "    \"useWeights\": True,\n",
    "    \"criticalRange\": (4., 8.),\n",
    "    \"images\": experiment_images,\n",
    "    \"backgroundImageS3Key\": sample_loc\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", job_url, headers=headers, json=payload)\n",
    "job_id = response.json()[\"jobId\"]\n",
    "\n",
    "signal_results = get_job_results(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef44653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_results.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f67495",
   "metadata": {},
   "source": [
    "## Step 7 - Understanding Results\n",
    "\n",
    "The signal detector produces a number of important insights into your data which includes raw values and visualizations. The two major visualizations produced are the `plotly_json` and `colordiff_json` payloads which can be immediately loaded and visualized using `plotly`. \n",
    "\n",
    "The `plotly_json` visual shows the ability of a computer to generate a predictive model on the colorimetric data you have provided. Each concentration will have its own boxplot that can be approximately interpreted in this way:\n",
    "\n",
    "* The y axis shows the percent deviation from the expected concentration when using a model to predict that value. Experience indicates that a y-axis value below 1 tends to lead to accurate production models.\n",
    "* The ability to develop a precise model can be viewed as a relationship of the vertical size of the boxplot. A box that spans a very small range of y-axis values indicates that predictions remain stable for that concentration across many simulation runs, whereas a box spanning a large range of values indicates the model struggles to produce consistent predictions for that concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from plotly import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d22ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_dict = signal_results.json()[0][\"resultData\"][\"plotly_json\"]\n",
    "io.from_json(json.dumps(plotly_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec0955c",
   "metadata": {},
   "source": [
    "In the `colordiff_json` visualization, the chart shows the difference in detected signal between the expected background and the reaction space. When there is no difference between the lines, this indicates that there is not enough difference between the background and the reaction space to reliably detect where the colorimetric data is present. Where the reaction line first diverges significantly from the background line can be thought of as the limit of detection for a particular assay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809b018",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_dict = signal_results.json()[0][\"resultData\"][\"colordiff_json\"]\n",
    "io.from_json(json.dumps(plotly_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc9ba50",
   "metadata": {},
   "source": [
    "In order to generate all the above metrics and visualizations, Monte Carlo simulations are run multiple times to accumulate information about model stability and performance. One useful statistic based on these simulations is the Coefficient of Variation. Although this is not the same as in a clinical or analytical chemistry experiment, it may provide users with a rough approximation of precision and repeatability for an assay at given concentrations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_metrics = signal_results.json()[0][\"resultData\"][\"statistics\"][\"additional_signals\"]\n",
    "x = []\n",
    "y = []\n",
    "for x_val, y_dict in cv_metrics.items():\n",
    "    x.append(float(x_val))\n",
    "    y.append(y_dict[\"%CV\"]*100)\n",
    "fig = px.bar(x, y, orientation = \"h\")\n",
    "\n",
    "fig.update_layout(\n",
    "                title=\"Coefficient of Variation\",\n",
    "                title_x=0.5,\n",
    "                yaxis_title=\"Concentration\",\n",
    "                xaxis_title=\"Variation (%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
